{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b162f97a",
   "metadata": {},
   "source": [
    "1.Sentences\n",
    "2.One hot Representation-- index from the dictionary\n",
    "3.Onhot Repre----> Embedding layer Keras to form Embedding Matrix\n",
    "4.Embedding matrix\n",
    "vocab_size=10000, dimension=10\n",
    "if we give index of 2000(Word) it will get coverted into dimension of 10 vector\n",
    "        man  women  child  king   queen\n",
    "gender  -1     1      0   -0.92   0.93  \n",
    "royal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b78ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b5b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Sentences\n",
    "sent = ['the glass of milk',\n",
    "        'the glass of juice',\n",
    "        'the cup of tea',\n",
    "        'I am a good boy',\n",
    "        'I am a good developer',\n",
    "        'understand the meaning of words',\n",
    "        'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7feb22bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulary size that is total number of unique words in the text + 1 (for padding)\n",
    "voc_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282cb48",
   "metadata": {},
   "source": [
    "One Hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9e343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9508, 6806, 5768, 7149], [9508, 6806, 5768, 3408], [9508, 5279, 5768, 9401], [6067, 9596, 7296, 9109, 8791], [6067, 9596, 7296, 9109, 5057], [5728, 9508, 5617, 5768, 8533], [1156, 1874, 2425, 9109]]\n"
     ]
    }
   ],
   "source": [
    "#One hot representation of the sentences that is converting the words into numbers based on the index in the vocabulary list\n",
    "onehot_repr=[one_hot(words,voc_size)for words in sent]\n",
    "print(onehot_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b9135",
   "metadata": {},
   "source": [
    "Word Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83b26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff4f3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d977b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 9508 6806 5768 7149]\n",
      " [   0    0    0    0 9508 6806 5768 3408]\n",
      " [   0    0    0    0 9508 5279 5768 9401]\n",
      " [   0    0    0 6067 9596 7296 9109 8791]\n",
      " [   0    0    0 6067 9596 7296 9109 5057]\n",
      " [   0    0    0 5728 9508 5617 5768 8533]\n",
      " [   0    0    0    0 1156 1874 2425 9109]]\n"
     ]
    }
   ],
   "source": [
    "#Here we are padding the sentences to make them of same length. We are using pre padding that is adding zeros at the beginning of the sentences. We are also specifying the maximum length of the sentences as 8. If the sentences are less than 8 then it will add zeros at the beginning and if the sentences are more than 8 then it will truncate the sentences from the beginning.\n",
    "sent_length=8\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model and adding the embedding layer. \n",
    "# The embedding layer takes the vocabulary size, the dimension of the embedding and the input length as parameters. \n",
    "# The input length is the length of the sentences after padding. The embedding layer will convert the one hot representation of the sentences into dense vectors of fixed size. \n",
    "# The dimension of the embedding is the size of the dense vectors that we want to create for each word in the vocabulary. \n",
    "# The embedding layer will learn the weights of the dense vectors during the training process.\n",
    "#Below we consider the dimension of the embedding as 15 that is we want to create dense vectors of size 15 for each word in the vocabulary.\n",
    "dim=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76de14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91600\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Below here we are creating the model and adding the embedding layer. We are also compiling the model with adam optimizer and mean squared error as the loss function.\n",
    "#Embedding layer will take the vocabulary size, the dimension of the embedding and the input length as parameters. \n",
    "#The input length is the length of the sentences after padding. The embedding layer will convert the one hot representation of the sentences into dense vectors of fixed size. \n",
    "#The dimension of the embedding is the size of the dense vectors that we want to create for each word in the vocabulary. \n",
    "#The embedding layer will learn the weights of the dense vectors during the training process.\n",
    "#And finally we are printing the summary of the model and the output of the model for the embedded documents.\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cefc386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fccb411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step\n",
      "[[[ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [-0.04514324 -0.00707488  0.04178245  0.00214205  0.02702547\n",
      "   -0.03632627  0.00985998  0.02848883 -0.04256867 -0.04205769\n",
      "   -0.02253145 -0.0156762  -0.01599034  0.00981622  0.0320742 ]\n",
      "  [ 0.01562745 -0.00184443  0.0460724   0.02715443 -0.01415005\n",
      "   -0.03025323  0.00584323 -0.04962739 -0.04077636  0.01918663\n",
      "   -0.04845819 -0.04177847 -0.02331861 -0.04746775 -0.02195215]\n",
      "  [-0.02093428  0.00176281  0.04692191  0.03623993 -0.04330322\n",
      "   -0.01136489 -0.00666902 -0.02502052 -0.037656    0.02075097\n",
      "    0.04321256  0.02573881  0.0135421   0.00910587 -0.00510856]\n",
      "  [ 0.04891206 -0.00987145  0.01608987 -0.03234171  0.00126601\n",
      "   -0.01626434 -0.01287473  0.00044271  0.01147147  0.04302349\n",
      "    0.0225275   0.02266679  0.02210302 -0.04880445  0.04450602]]\n",
      "\n",
      " [[ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [-0.04514324 -0.00707488  0.04178245  0.00214205  0.02702547\n",
      "   -0.03632627  0.00985998  0.02848883 -0.04256867 -0.04205769\n",
      "   -0.02253145 -0.0156762  -0.01599034  0.00981622  0.0320742 ]\n",
      "  [ 0.01562745 -0.00184443  0.0460724   0.02715443 -0.01415005\n",
      "   -0.03025323  0.00584323 -0.04962739 -0.04077636  0.01918663\n",
      "   -0.04845819 -0.04177847 -0.02331861 -0.04746775 -0.02195215]\n",
      "  [-0.02093428  0.00176281  0.04692191  0.03623993 -0.04330322\n",
      "   -0.01136489 -0.00666902 -0.02502052 -0.037656    0.02075097\n",
      "    0.04321256  0.02573881  0.0135421   0.00910587 -0.00510856]\n",
      "  [-0.00422909  0.02563209 -0.0176492  -0.04673395  0.01085674\n",
      "    0.0236463  -0.01190443 -0.00621182 -0.04248737 -0.01220077\n",
      "   -0.03758057 -0.02490008  0.00453888  0.02453515  0.03740415]]\n",
      "\n",
      " [[ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [-0.04514324 -0.00707488  0.04178245  0.00214205  0.02702547\n",
      "   -0.03632627  0.00985998  0.02848883 -0.04256867 -0.04205769\n",
      "   -0.02253145 -0.0156762  -0.01599034  0.00981622  0.0320742 ]\n",
      "  [ 0.01613228 -0.01905754 -0.04617178 -0.02060604  0.00604142\n",
      "    0.0047402   0.01670721  0.01965017 -0.00730512 -0.02632627\n",
      "    0.0106582   0.00720365  0.03027909  0.03178613  0.01584092]\n",
      "  [-0.02093428  0.00176281  0.04692191  0.03623993 -0.04330322\n",
      "   -0.01136489 -0.00666902 -0.02502052 -0.037656    0.02075097\n",
      "    0.04321256  0.02573881  0.0135421   0.00910587 -0.00510856]\n",
      "  [ 0.02617881 -0.00777396 -0.00956818 -0.01299367 -0.00636221\n",
      "    0.01590443 -0.00891423 -0.00264993 -0.02212792  0.03985543\n",
      "   -0.03243567 -0.01706992  0.00548498 -0.00786952  0.02935273]]\n",
      "\n",
      " [[ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [-0.00683683  0.04626441 -0.02096479  0.04948343  0.04586682\n",
      "    0.04712549 -0.00119834  0.02571572 -0.03663016  0.01353005\n",
      "    0.00070613  0.01136047  0.00764944  0.02013666  0.00207313]\n",
      "  [-0.00324843  0.03634251  0.00662098  0.0102881  -0.04299093\n",
      "   -0.01629744 -0.0459121   0.02097789 -0.03892616  0.02933577\n",
      "    0.02993566 -0.03032475 -0.0109807  -0.04784543 -0.02646788]\n",
      "  [-0.02113857  0.01622157  0.02801449  0.03490149 -0.01835698\n",
      "   -0.0144675  -0.04310651  0.02102489 -0.04924181 -0.02738128\n",
      "   -0.01858117 -0.03847187  0.03828511  0.04643743 -0.03112371]\n",
      "  [ 0.03011035 -0.02329102  0.03940144  0.00690905  0.02918886\n",
      "   -0.0271566  -0.00792034 -0.03691804 -0.01939323  0.03624717\n",
      "   -0.03261085 -0.01984139  0.03073192  0.00073041 -0.00827879]\n",
      "  [ 0.02741661 -0.02765466 -0.03126276  0.02475972 -0.03899642\n",
      "    0.03654357 -0.00693415 -0.04048461  0.00047331  0.02658736\n",
      "   -0.03389909 -0.01493312  0.01305843 -0.0117888  -0.00424566]]\n",
      "\n",
      " [[ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [-0.00683683  0.04626441 -0.02096479  0.04948343  0.04586682\n",
      "    0.04712549 -0.00119834  0.02571572 -0.03663016  0.01353005\n",
      "    0.00070613  0.01136047  0.00764944  0.02013666  0.00207313]\n",
      "  [-0.00324843  0.03634251  0.00662098  0.0102881  -0.04299093\n",
      "   -0.01629744 -0.0459121   0.02097789 -0.03892616  0.02933577\n",
      "    0.02993566 -0.03032475 -0.0109807  -0.04784543 -0.02646788]\n",
      "  [-0.02113857  0.01622157  0.02801449  0.03490149 -0.01835698\n",
      "   -0.0144675  -0.04310651  0.02102489 -0.04924181 -0.02738128\n",
      "   -0.01858117 -0.03847187  0.03828511  0.04643743 -0.03112371]\n",
      "  [ 0.03011035 -0.02329102  0.03940144  0.00690905  0.02918886\n",
      "   -0.0271566  -0.00792034 -0.03691804 -0.01939323  0.03624717\n",
      "   -0.03261085 -0.01984139  0.03073192  0.00073041 -0.00827879]\n",
      "  [-0.03741022  0.02593095  0.01741279 -0.00256879  0.03557824\n",
      "    0.03990513 -0.0399812  -0.02581182  0.03367219 -0.00604201\n",
      "   -0.00693368 -0.03865027 -0.00146508 -0.01268359  0.04186232]]\n",
      "\n",
      " [[ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [-0.04502567  0.03445581  0.03222145 -0.03194097 -0.00794903\n",
      "   -0.03515667 -0.01464138 -0.04876443 -0.00438651 -0.00611209\n",
      "   -0.01955944  0.02174595  0.01560967  0.00563378  0.01403067]\n",
      "  [-0.04514324 -0.00707488  0.04178245  0.00214205  0.02702547\n",
      "   -0.03632627  0.00985998  0.02848883 -0.04256867 -0.04205769\n",
      "   -0.02253145 -0.0156762  -0.01599034  0.00981622  0.0320742 ]\n",
      "  [-0.03576601  0.02738161  0.00762354 -0.02448168 -0.00679167\n",
      "   -0.00224384  0.02105493  0.00454912 -0.01204855 -0.00734669\n",
      "    0.03031984 -0.00060177  0.02820574 -0.02027136 -0.04591836]\n",
      "  [-0.02093428  0.00176281  0.04692191  0.03623993 -0.04330322\n",
      "   -0.01136489 -0.00666902 -0.02502052 -0.037656    0.02075097\n",
      "    0.04321256  0.02573881  0.0135421   0.00910587 -0.00510856]\n",
      "  [ 0.02186617  0.00023454  0.01831735  0.04107881 -0.019611\n",
      "   -0.03483559  0.02921145 -0.04175078  0.04366532  0.0198085\n",
      "    0.02497505 -0.02889606  0.01867938  0.03007294 -0.03297721]]\n",
      "\n",
      " [[ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202\n",
      "    0.00842609  0.01184658 -0.00775087  0.02415187 -0.02206247\n",
      "   -0.00237995  0.04742617 -0.04739143 -0.03433185 -0.02247335]\n",
      "  [-0.04664421 -0.03412628  0.03213544 -0.00433179 -0.02973652\n",
      "   -0.04773659 -0.00389972  0.01873207  0.00875665  0.0329153\n",
      "   -0.00126517 -0.0005533   0.02176786 -0.04199599  0.04880385]\n",
      "  [-0.03273313  0.02560899  0.01349521 -0.01489317 -0.00525411\n",
      "    0.0178699   0.00743796  0.02169397  0.02170614 -0.00950475\n",
      "    0.00294073 -0.04074588  0.04293678 -0.00457485 -0.03268454]\n",
      "  [ 0.03602679 -0.03934041 -0.02808745  0.03540182 -0.02241293\n",
      "    0.02866646 -0.00541917 -0.04265178  0.02061728  0.00127339\n",
      "    0.02287919  0.02858071  0.02873962  0.0413294  -0.02656767]\n",
      "  [ 0.03011035 -0.02329102  0.03940144  0.00690905  0.02918886\n",
      "   -0.0271566  -0.00792034 -0.03691804 -0.01939323  0.03624717\n",
      "   -0.03261085 -0.01984139  0.03073192  0.00073041 -0.00827879]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24cf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0, 9508, 6806, 5768, 7149], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The sentence at index 0 is 'the glass of milk' and the one hot representation of this sentence is [1, 2, 3, 4] and after padding it becomes [0, 0, 0, 1, 2, 3, 4] and the output of the model for this sentence is a dense vector of size 15 for each word in the sentence. So the output for this sentence will be a matrix of size (8, 15) where 8 is the length of the sentence after padding and 15 is the dimension of the embedding.\n",
    "#that means it will create a dense vector of size 15 for each word in the sentence and the total number of words in the sentence after padding is 8. So the output will be a matrix of size (8, 15) for each sentence in the embedded documents.\n",
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ebb2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "[[ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202  0.00842609\n",
      "   0.01184658 -0.00775087  0.02415187 -0.02206247 -0.00237995  0.04742617\n",
      "  -0.04739143 -0.03433185 -0.02247335]\n",
      " [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202  0.00842609\n",
      "   0.01184658 -0.00775087  0.02415187 -0.02206247 -0.00237995  0.04742617\n",
      "  -0.04739143 -0.03433185 -0.02247335]\n",
      " [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202  0.00842609\n",
      "   0.01184658 -0.00775087  0.02415187 -0.02206247 -0.00237995  0.04742617\n",
      "  -0.04739143 -0.03433185 -0.02247335]\n",
      " [ 0.00706352  0.0032776  -0.03449382  0.03835898  0.01634202  0.00842609\n",
      "   0.01184658 -0.00775087  0.02415187 -0.02206247 -0.00237995  0.04742617\n",
      "  -0.04739143 -0.03433185 -0.02247335]\n",
      " [-0.04514324 -0.00707488  0.04178245  0.00214205  0.02702547 -0.03632627\n",
      "   0.00985998  0.02848883 -0.04256867 -0.04205769 -0.02253145 -0.0156762\n",
      "  -0.01599034  0.00981622  0.0320742 ]\n",
      " [ 0.01562745 -0.00184443  0.0460724   0.02715443 -0.01415005 -0.03025323\n",
      "   0.00584323 -0.04962739 -0.04077636  0.01918663 -0.04845819 -0.04177847\n",
      "  -0.02331861 -0.04746775 -0.02195215]\n",
      " [-0.02093428  0.00176281  0.04692191  0.03623993 -0.04330322 -0.01136489\n",
      "  -0.00666902 -0.02502052 -0.037656    0.02075097  0.04321256  0.02573881\n",
      "   0.0135421   0.00910587 -0.00510856]\n",
      " [ 0.04891206 -0.00987145  0.01608987 -0.03234171  0.00126601 -0.01626434\n",
      "  -0.01287473  0.00044271  0.01147147  0.04302349  0.0225275   0.02266679\n",
      "   0.02210302 -0.04880445  0.04450602]]\n"
     ]
    }
   ],
   "source": [
    "#Here we are printing the output of the model for the first sentence in the embedded documents. The output will be a matrix of size (8, 15) where 8 is the length of the sentence after padding and 15 is the dimension of the embedding.\n",
    "#each word in the sentence will be represented as a dense vector of size 15 and the total number of words in the sentence after padding is 8. So the output will be a matrix of size (8, 15) for the first sentence in the embedded documents.\n",
    "print(model.predict(embedded_docs)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
